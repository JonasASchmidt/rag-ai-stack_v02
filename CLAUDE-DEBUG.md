Ich habe einen lokalen RAG AI Chat Stack mit Hilfe von OpenAIs Codex aufgebaut und arbeite innerhalb eines git repos mit ihm daran. Allerdings funktioniert der Stack noch nicht wirklich. Die grundsätzliche Infrastruktur und das Rahmenwerk scheinen zu stehen und die Chat-App läuft auch, aber wenn ich etwas eingebe scheint die Server-Verbindung nicht zu funktionieren oder die Performance ist das Problem. Ich kann alle Modelle per CLI und auch per Ollama Desktop-App problemlos performant nutzen, aber wenn Fragen im Chat stelle, bekomme ich keine Antwort. 

Die grundsätzliche idee der App ist (auch im Repo in CONCEPT.md enthalten) dass ich Dokumente in einem Verzeichnis ablege, diese von einem Python script indizieren (ingesten) lasse, das sie in einem Vector-Store aufbereitet, für die KI, der ich dann im Chat Fragen zum Inhalte der Dokumente stellen kann. Diese soll über die Fragestellung nachdenken und schlau den Dokument-Index befragen und dann smarte und relevante Antworten ohne Halluzinationen geben, auf Basis der Informationen in den Dokumenten. Es soll auch möglich sein in der Chat-Session Dokumente hoch zu laden, die dann im /docs-Verzeichnis landen und indiziert werden, so dass die KI Zugriff auf Ihre Inhalte hat.

Ich glaube ich habe viele relevante Bestandteile die einen solchen Stack ausmachen und gut funktionieren lassen, aber einige schienen noch zu fehlen. Zudem weiß ich nicht genau welche Codex schon implementiert und welche er nur vorbereitet hat. 

Codellama hat mir zum Beispiel von den folgenden Themen erzählt, von denen ich noch nicht wirklich wusste:

Choose an NLP library: There are several NLP libraries available that you can use to build your AI stack. Some popular choices include spaCy, NLTK, and Stanford CoreNLP. These libraries provide pre-trained models and tools for tokenization, parsing, and entity recognition.
Develop a text classification model: You can develop a text classification model using the chosen library to classify questions into different categories based on their content. This will help your AI stack understand which questions it should answer from the ones that require more complex reasoning.
Build a knowledge graph: You can create a knowledge graph by ingesting documents and storing them in a database. The knowledge graph should contain information about the entities, relationships, and categories present in the documents. This will help your AI stack provide accurate answers to questions based on the ingested documents.
Develop a reasoning engine: You can develop a reasoning engine that uses the knowledge graph to provide accurate answers to questions. The reasoning engine can use inference rules or logical reasoning techniques to derive an
Moderne Software-Architektur und Coding-Prinzipien, ein modularer Aufbau der technology lock-in vermeidet und erweiterbar ist und innerhalb dessen einzelne Funktionsmodule weiderverwendbar und Austausch- und erweiterbar sind, ist mir wichtig. Moderne Coding-Prinzipien und Code-Konventionen sollen eingehalten werden und grundlegende Tests existieren. Aber von allem nur das nötige, damit die App übersichtlich, möglichst einfach strukturiert und leichtgewichtig bleibt. Außerdem sind mir performance, Verlässlichkeit und UX (user experience) extrem wichtig.

Da ich mit Codex jetzt schon länger an der App arbeite aber noch nicht einmal einfache Antworten auf Basis der Dokumente erhalte, wollte ich Dich bitten die App insgesamt zu reviewen und mir Schrittweise Verbesserungsvorschläge zu machen um sie zum Laufen zu bringen. Iterativ und agil, so dass jedes Increment grundsätzlich lauffähig ist und der Core-Use-Case immer funktioniert.

Hier ist der Link zum entsprechenden Repo: https://github.com/JonasASchmidt/rag-ai-stack_v02